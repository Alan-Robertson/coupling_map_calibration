{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69a00e86",
   "metadata": {},
   "source": [
    "## Correlated and Biased Simulated Measurement Errors on BV ##\n",
    "This notebook runs a number of experiments using different measurement error mitigation strategies against an implementation of the Bernstein-Vazirani algorithm where all oracles produce states in the measurement basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd37579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qiskit does not play nicely with modern numpy\n",
    "import warnings\n",
    "\n",
    "warnings.catch_warnings() \n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "\n",
    "# Mainline Python Imports\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import copy\n",
    "import sys, os, time\n",
    "\n",
    "from typing import Callable\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "# Plotting Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import seaborn as sbs\n",
    "\n",
    "sbs.set(style=\"darkgrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "from qutip import *\n",
    "import scipy\n",
    "\n",
    "# Qiskit Imports\n",
    "import qiskit\n",
    "from qiskit import IBMQ\n",
    "from qiskit import transpile, QuantumRegister, assemble\n",
    "from qiskit import QuantumCircuit, execute, Aer, QuantumCircuit\n",
    "from qiskit.ignis.mitigation.measurement import complete_meas_cal, tensored_meas_cal, CompleteMeasFitter, TensoredMeasFitter\n",
    "import qiskit.ignis.verification.randomized_benchmarking as rb\n",
    "\n",
    "IBMQ.load_account()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5705c6e8",
   "metadata": {},
   "source": [
    "### A quick and dirty progress bar ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-supervision",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "\n",
    "class Pbar():\n",
    "    '''\n",
    "        Simple progress bar class\n",
    "    '''\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            n_ticks, # Number of ticks to print\n",
    "            n_calls, # Number of times you expect to call this progress bar\n",
    "            name='', # Name of bar to display\n",
    "            ticker='=', # Ticker symbol(s)\n",
    "            ticker_head='>', # Head of the ticker\n",
    "            ticker_blank=' '): # Unticked symbol(s)\n",
    "        self.n_ticks = n_ticks\n",
    "        self.n_calls = n_calls\n",
    "        self.name = name\n",
    "        self.ticker=ticker\n",
    "        self.ticker_head = ticker_head\n",
    "        self.ticker_blank = ticker_blank\n",
    "        self.p_len = 0 # Length of previous print\n",
    "        self.invoked = 0 # Has it been called yet?\n",
    "\n",
    "    def __call__(self, message=''):\n",
    "\n",
    "\n",
    "        print('\\b' * self.p_len  , end='', flush=True) # Flush previous print\n",
    "\n",
    "        ticker = floor(self.invoked / self.n_calls * self.n_ticks) * self.ticker\n",
    "        blank = (self.n_ticks - len(ticker) - 1) * self.ticker_blank\n",
    "        head = [self.ticker_head, ''][len(ticker) >= self.n_ticks]\n",
    "\n",
    "        fstring = \"\\r{name} : [{ticker}{head}{blank}] {msg}\".format(\n",
    "                name = self.name,\n",
    "                ticker = ticker,\n",
    "                head = head,\n",
    "                blank = blank, \n",
    "                msg = message\n",
    "                )\n",
    "        self.p_len = len(fstring) + 15\n",
    "        print(fstring, end='', flush=True)\n",
    "        self.invoked += 1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8e82f0",
   "metadata": {},
   "source": [
    "A circuit constructor that applies a given inversion array and then adds measurements.\n",
    "The inversion array is needed for AIM and SIM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4367b22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def design_circuit(n_qubits, inv_arr, circuit=None):\n",
    "    '''\n",
    "        Given a circuit and an inversion array apply X on all 1 values in the array then measure all qubits\n",
    "    '''\n",
    "    \n",
    "    # No circuit, make a bare one\n",
    "    if circuit is None:\n",
    "        circuit = QuantumCircuit(n_qubits, n_qubits)\n",
    "    \n",
    "    # Apply flips from inv_array\n",
    "    for i, element in enumerate(inv_arr):\n",
    "        if int(element) == 1:\n",
    "            circuit.x(i)\n",
    "    \n",
    "    # Measure all qubits\n",
    "    circuit.measure(list(range(n_qubits)), list(range(n_qubits)))\n",
    "    \n",
    "    return circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e800d30",
   "metadata": {},
   "source": [
    "Constructs a BV circuit with an oracle that constructs the state described by the bv string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab007a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bv_circuit(bv_string : str, n_qubits : int):\n",
    "    '''\n",
    "        Returns a BV circuit that prepares the state bv_string over n_qubits\n",
    "        :: bv_string ::\n",
    "        :: n_qubits\n",
    "    '''\n",
    "    bv_circuit = QuantumCircuit(n_qubits, n_qubits - 1)\n",
    "\n",
    "    # Hadamard on all participating qubits\n",
    "    for i in range(n_qubits):\n",
    "        bv_circuit.h(i)\n",
    "\n",
    "    bv_circuit.z(n_qubits - 1)\n",
    "\n",
    "    bv_circuit.barrier()\n",
    "\n",
    "    # Oracle to construct state\n",
    "    # Performs a CNOT from the target qubit to the ensemble\n",
    "    for i in range(n_qubits - 1):\n",
    "        if bv_string[i] == '1':\n",
    "            bv_circuit.cx(i, n_qubits - 1)\n",
    "\n",
    "\n",
    "    # Barrier to prevent optimisations over pairs of hadarmards, oracle is *supposed* to be blind\n",
    "    bv_circuit.barrier()\n",
    "\n",
    "    # Hadamard on all participating qubits\n",
    "    for i in range(n_qubits - 1):\n",
    "        bv_circuit.h(i)\n",
    "\n",
    "    return bv_circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-sydney",
   "metadata": {},
   "source": [
    "## Sampling Methods ##\n",
    "For sampling simulated measurement errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-struggle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_distribution(population : dict, n_shots : int) -> dict:\n",
    "    '''\n",
    "        Distribution sampling method\n",
    "        Given an existing set of results, resample\n",
    "        Used for simulating measurement errors\n",
    "        \n",
    "        :: population : dict :: Current shot population to sample\n",
    "        :: n_shots    : int  :: Number of shots to take on the population\n",
    "    '''\n",
    "    # There are much more efficient ways to do this\n",
    "    \n",
    "    n_counts = sum(population.values())\n",
    "    vals = list(population.keys())\n",
    "    weights = np.array([population[i] / n_counts for i in vals])\n",
    "    \n",
    "    weights /= sum(weights)\n",
    "    \n",
    "    updated_population = weighted_sample_distribution(weights, vals, n_shots)\n",
    "    \n",
    "    return updated_population\n",
    "\n",
    "def weighted_sample_distribution(weights : list, values : list, n_shots : int) -> dict:\n",
    "    '''\n",
    "        weighted_sample_distribution\n",
    "        Distribution sampling method\n",
    "        Given an existing set of results and weights, resample\n",
    "        Used for simulating measurement errors\n",
    "        \n",
    "        :: weights : list :: Current shot population to sample\n",
    "        :: values  : list :: Values associated with each weight\n",
    "        :: n_shots : int  :: Number of shots to take on the population\n",
    "    '''\n",
    "    out_distribution = {}\n",
    "    \n",
    "    # Normalise weights, just to be sure\n",
    "    weights /= sum(weights)\n",
    "    \n",
    "    # Rough check on sum of weights\n",
    "    assert(sum(weights) <= 1 or math.isclose(sum(weights), 1, abs_tol=1e-5))\n",
    "    \n",
    "    # Cumulative weights\n",
    "    c_weights = [0]\n",
    "    for weight in weights:\n",
    "        c_weights.append(weight + c_weights[-1])\n",
    "\n",
    "    # Take random shots at the distribution\n",
    "    for _ in range(n_shots):\n",
    "        v = np.random.random()\n",
    "\n",
    "        # This would be faster with a BST or some fancy hashing\n",
    "        for val, lower, upper in zip(values, c_weights[:-1], c_weights[1:]):\n",
    "        \n",
    "            # Check bound on random value\n",
    "            if v > lower and v < upper: \n",
    "                if val in out_distribution:\n",
    "                    out_distribution[val] += 1\n",
    "                else:\n",
    "                    out_distribution[val] = 1\n",
    "                break\n",
    "                \n",
    "    return out_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-checkout",
   "metadata": {},
   "source": [
    "## Simulated Measurement Error Channel ##\n",
    "Constructs measurement errors with statistical biases towards error weights and state dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5475b70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_error_probs(\n",
    "    error_arr_c : list, # Error distance weights\n",
    "    error_arr_u : list, # Error state dependent weights up\n",
    "    error_arr_d : list, # Error state dependent weights down\n",
    "    n_qubits = 4):\n",
    "    '''\n",
    "        gen_error_probs\n",
    "        \n",
    "        Function to generate error probabilities for simulated measurement errors\n",
    "        \n",
    "        :: error_arr_c : list :: Weights on error sizes\n",
    "        :: error_arr_u : list :: Weights on \"up\" state depentent errors\n",
    "        :: error_arr_d : list :: Weights on \"down\" state depentent errors\n",
    "        :: n_qubits    : int  :: Number of qubits\n",
    "        \n",
    "        Returns a measurement error channel\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Build initial prob vector\n",
    "    probs = [[0] * (2 ** n_qubits) for _ in range(2 ** n_qubits)]\n",
    "    \n",
    "    # Check size of weights\n",
    "    if len(error_arr_c) != n_qubits + 1:\n",
    "        raise Exception(\"Incorrect Error Array\")\n",
    "    \n",
    "    if len(error_arr_u) != n_qubits + 1:\n",
    "        raise Exception(\"Incorrect Error Array\")\n",
    "        \n",
    "        \n",
    "    if len(error_arr_d) != n_qubits + 1:\n",
    "        raise Exception(\"Incorrect Error Array\")\n",
    "    \n",
    "    # Fill vector\n",
    "    for row in range(2 ** n_qubits):\n",
    "        row_str = bin(row)[2:].zfill(n_qubits)\n",
    "\n",
    "\n",
    "        for col in range(2 ** n_qubits):\n",
    "            col_str = bin(col)[2:].zfill(n_qubits)\n",
    "\n",
    "            diff_str = [i - j for i, j in zip(list(map(int, row_str)), list(map(int, col_str)))]   \n",
    "            \n",
    "            probs[row][col] += error_arr_u[sum(1 if i == -1 else 0 for i in diff_str)]\n",
    "            probs[row][col] += error_arr_d[sum(1 if i == 1 else 0 for i in diff_str)]\n",
    "            probs[row][col] += error_arr_c[n_qubits - sum(1 if i == 0 else 0 for i in diff_str)]\n",
    "            \n",
    "            probs[row][col] = max(0, probs[row][col])\n",
    "            \n",
    "    #Normalise rows, we can then do arbitrary scaling factors in the error arr\n",
    "    for row, _ in enumerate(probs):\n",
    "        np_row = np.array(probs[row])\n",
    "        if sum(np_row) > 0:\n",
    "            np_row = np_row / sum(np_row) \n",
    "        probs[row] = list(np_row)\n",
    "\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-acrylic",
   "metadata": {},
   "source": [
    "Example measurement error channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-isaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gen_error_probs(\n",
    "        [100,30,0,0,0], # Const - Controls correlation of error weights\n",
    "        [0, 5, 30, 5, 5], # 0 -> 1 - Controls state dependent errors\n",
    "        [0, 0, 0, 0, 0] # 1 -> 0 - Controls state dependent errors\n",
    "        )\n",
    "sbs.heatmap(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f09bf33",
   "metadata": {},
   "source": [
    "### Measurement Error Application Functions ###\n",
    "Act to apply measurement errors to dict representations or results representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de68fa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisy_measure(\n",
    "    counts : dict, \n",
    "    probs=gen_error_probs(\n",
    "        [100,5,0,0,0], # Const - Controls correlation of error weights\n",
    "        [0, 0, 0, 0, 0], # 1 -> 0 - Controls error biases\n",
    "        [0, 0, 0, 0, 0] # 0 -> 1 - Controls error biases\n",
    "        ),\n",
    "    n_qubits=4\n",
    "    ) -> dict:\n",
    "    \n",
    "    '''\n",
    "        noisy_measure\n",
    "        Simulated noisy measurement\n",
    "        \n",
    "        :: counts   : dict :: Measurement results\n",
    "        :: probs    : list :: Measurement error probabilities\n",
    "        :: n_qubits : int  :: Number of qubits\n",
    "        \n",
    "        Returns a dictionary of measurement results\n",
    "    '''\n",
    "    \n",
    "    # Vector of measurment outcomes\n",
    "    vec = np.zeros((2 ** n_qubits, 1))\n",
    "    for i in range(2 ** n_qubits):\n",
    "        try:\n",
    "            vec[i][0] = counts[str(bin(i)[2:].zfill(n_qubits))]\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    vals = [bin(i)[2:].zfill(n_qubits) for i in range(2 ** n_qubits)]\n",
    "    \n",
    "    n_shots = sum(counts.values())\n",
    "    \n",
    "    weights = (probs @ (vec / n_shots)).flatten()\n",
    "    counts_final = weighted_sample_distribution(weights, vals, n_shots)\n",
    "\n",
    "    return counts_final\n",
    "\n",
    "\n",
    "\n",
    "def measurement_error(counts, n_qubits=4, probs = gen_error_probs(\n",
    "        [100,10,40,1,1], # Const - Controls correlation of error weights\n",
    "        [0, 4,3,3,3], # 1 -> 0 - Controls error biases\n",
    "        [0,-5,-5,-5,-5] # 0 -> 1 - Controls error biases\n",
    "        )) -> dict:\n",
    "\n",
    "    '''\n",
    "        Just calls noisy measure\n",
    "        Probably should be deprecated\n",
    "    '''\n",
    "    \n",
    "    counts_final = noisy_measure(counts, n_qubits=n_qubits, probs=probs)\n",
    "    \n",
    "    return counts_final\n",
    "\n",
    "\n",
    "\n",
    "def cal_res_measurement_error(\n",
    "    cal_results,\n",
    "    probs : list,\n",
    "    n_qubits=4\n",
    "    ) -> dict:\n",
    "    \n",
    "    '''\n",
    "        cal_res_measurement_error\n",
    "        Calculates the output after applying a simulated measurement error\n",
    "        \n",
    "        :: cal_results : results object :: Results before the measurement error\n",
    "        :: probs       : list :: Measurement error to apply\n",
    "        :: n_qubits    : int  :: The number of qubits to apply over\n",
    "        \n",
    "        Acts in place on the cal_results object\n",
    "    '''\n",
    "    \n",
    "    # Loop over results and construct counts\n",
    "    for i, res in enumerate(cal_results.results):\n",
    "        d = {}\n",
    "        cd = res.data.to_dict()['counts']\n",
    "        for key in cd:\n",
    "            d[bin(int(key, 16))[2:].zfill(n_qubits)] = cd[key]\n",
    "        \n",
    "        # Apply measurement errors to the counts\n",
    "        counts = measurement_error(d, n_qubits=n_qubits, probs=probs)\n",
    "\n",
    "        # Fix the keys back to hex formatting\n",
    "        data_counts = {}\n",
    "        for key in counts:\n",
    "            data_counts[hex(int(key, 2))] = counts[key]\n",
    "        cal_results.results[i].data.counts = data_counts\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf1e71d",
   "metadata": {},
   "source": [
    "## Measurement Error Mitigation Strategies ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77add88",
   "metadata": {},
   "source": [
    "### No Correction ###\n",
    "Simply run and report the baseline error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-grounds",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_correction(circuit, \n",
    "                  probs=None, \n",
    "                  n_shots=1000,\n",
    "                  n_qubits=4) -> dict:\n",
    "    '''\n",
    "        No correction baseline\n",
    "        Simply performs the circuits and reports the results\n",
    "    '''\n",
    "    tmp_circuit = copy.deepcopy(circuit)\n",
    "    tmp_circuit = design_circuit(n_qubits, '0' * n_qubits, circuit=tmp_circuit)\n",
    "\n",
    "    job = execute(tmp_circuit, backend, shots=n_shots)\n",
    "\n",
    "    results = job.result().get_counts()\n",
    "\n",
    "    if probs is not None:\n",
    "        noisy_measurement = measurement_error(results, n_qubits=n_qubits, probs=probs)\n",
    "        results = sample_distribution(noisy_measurement, n_shots)\n",
    "\n",
    "    # Result strings are in reverse order\n",
    "    qiskit_results_qubit_order = {}\n",
    "    for i in results:\n",
    "        qiskit_results_qubit_order[i[::-1]] = results[i]\n",
    "    return qiskit_results_qubit_order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f3b9f2",
   "metadata": {},
   "source": [
    "### SIM ###\n",
    "Average over a set of measurement operators to try to mitigate state dependent errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46acc2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIM for even numbers of measured qubits \n",
    "def sim(circuit, \n",
    "        probs=None,\n",
    "        n_shots=1000,\n",
    "        n_qubits=4) -> dict:\n",
    "    '''\n",
    "        SIM\n",
    "        Construct four target measurement inv_arrays and average results over them\n",
    "        This implementation works for even numbers of measured qubits, sim_strs would need to be modified for \n",
    "        the odd case\n",
    "        \n",
    "        :: circuit  :: Circuit to perform SIM over\n",
    "        :: probs    :: Simulated error channel to apply\n",
    "        :: n_shots  :: Number of shots to take\n",
    "        :: n_qubits :: Number of qubits to measure\n",
    "        \n",
    "        Returns the shot statistics following SIM\n",
    "    '''\n",
    "\n",
    "    # Construct inv_arrays\n",
    "    sim_strs = [\n",
    "        [0] * n_qubits, \n",
    "        [1] * n_qubits,\n",
    "        [0, 1] * (n_qubits // 2), \n",
    "        [1, 0] * (n_qubits // 2)\n",
    "    ]\n",
    "    \n",
    "    # Number of shots per inv_array\n",
    "    shots = n_shots // len(sim_strs)\n",
    "    \n",
    "    sim_results = {}\n",
    "    for inversion_arr in sim_strs:\n",
    "    \n",
    "        # New circuit per inv array\n",
    "        tmp_circuit = copy.deepcopy(circuit)\n",
    "        tmp_circuit = design_circuit(n_qubits, inversion_arr, circuit=tmp_circuit)\n",
    "\n",
    "        job = execute(tmp_circuit, backend, shots=shots)\n",
    "\n",
    "        results = job.result().get_counts()\n",
    "\n",
    "        # Apply simulated measurement errors\n",
    "        if probs is not None:\n",
    "            noisy_measurement = measurement_error(results, n_qubits=n_qubits, probs=probs)\n",
    "            results = sample_distribution(noisy_measurement, shots)\n",
    "        \n",
    "        # Join results for averaging\n",
    "        for count in results:\n",
    "            # Invert SIM strings\n",
    "            count_arr = ''.join(map(str, [i ^ j for i, j in zip(inversion_arr, map(int, list(count[::-1])))]))\n",
    "\n",
    "            if count_arr in sim_results:\n",
    "                sim_results[count_arr] += results[count]\n",
    "            else:\n",
    "                sim_results[count_arr] = results[count]\n",
    "\n",
    "    return sim_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7848bf9e",
   "metadata": {},
   "source": [
    "## AIM ##\n",
    "Select a subset \"top-k\" of measurement operators and average over those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b074540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIM\n",
    "def aim(circuit, \n",
    "        probs=None, # Simulated error channel\n",
    "        n_shots=1000, # Number of shots\n",
    "        n_qubits=4, # Number of qubits to measure\n",
    "        k=4 # Top k strings\n",
    "       ) -> dict:\n",
    "    '''\n",
    "        AIM\n",
    "        Performs adaptive invert and measure on a target circuit\n",
    "        :: circuit  :: Circuit to perform AIM over\n",
    "        :: probs    :: Simulated error channel to apply\n",
    "        :: n_shots  :: Number of shots to take\n",
    "        :: n_qubits :: Number of qubits to measure\n",
    "        :: k        :: Top k inversion strings to use\n",
    "        \n",
    "        Returns the shot statistics following AIM\n",
    "    '''\n",
    "    \n",
    "    confirmation_shots = n_shots // k\n",
    "    \n",
    "    \n",
    "    # Build AIM strings\n",
    "    aim_strs = [[0] * n_qubits for _ in range(n_qubits)]\n",
    "    \n",
    "    # Running on four qubits here, so rather than [0000, 1111] we'll run 1000, 0100 etc\n",
    "    # Could probably compare to 1100, 0110, 0011, 1001\n",
    "    for i in range(len(aim_strs)):\n",
    "        aim_strs[i][i] = 1\n",
    "    aim_strs += [[0] * n_qubits]\n",
    "\n",
    "    # Number of shots per string\n",
    "    shots = n_shots // len(aim_strs)\n",
    "    \n",
    "    aim_results = {}\n",
    "    for inversion_arr in aim_strs:\n",
    "    \n",
    "        # Build and execute AIM circuits\n",
    "        tmp_circuit = copy.deepcopy(circuit)\n",
    "        tmp_circuit = design_circuit(n_qubits, inversion_arr, circuit=tmp_circuit)\n",
    "        job = execute(tmp_circuit, backend, shots=shots)\n",
    "        results = job.result().get_counts()\n",
    "\n",
    "        # Simulated Noisy Measurement\n",
    "        if probs is not None:\n",
    "            noisy_measurement = measurement_error(results, n_qubits=n_qubits, probs=probs)\n",
    "            results = sample_distribution(noisy_measurement, shots)\n",
    "\n",
    "        # Invert AIM Strings\n",
    "        aim_result = {}\n",
    "        for count in results:\n",
    "            count_arr = ''.join(map(str, [i ^ j for i, j in zip(inversion_arr, map(int, list(count[::-1])))]))\n",
    "\n",
    "            if count_arr in aim_result:\n",
    "                aim_result[count_arr] += results[count]\n",
    "            else:\n",
    "                aim_result[count_arr] = results[count]\n",
    "\n",
    "        aim_results[''.join(map(str, inversion_arr))] = aim_result\n",
    "    \n",
    "    # Join across inversion strings\n",
    "    likelihoods = {}\n",
    "    for res in aim_results:\n",
    "        for state in aim_results[res]:\n",
    "            if state in likelihoods:\n",
    "                likelihoods[state] += aim_results[res][state]\n",
    "            else:\n",
    "                likelihoods[state] = aim_results[res][state]\n",
    "    \n",
    "    # Select top k strings\n",
    "    top_k = []\n",
    "    for i in range(k):\n",
    "        top = max(likelihoods.items(), key=lambda i: i[1])\n",
    "        top_k.append(top[0])\n",
    "        likelihoods.pop(top[0])\n",
    "    \n",
    "\n",
    "    # Run confirmation shots for statistics\n",
    "    tmp_circuits = [copy.deepcopy(circuit) for _ in range(k)]\n",
    "    tmp_circuits = [design_circuit(n_qubits, i, circuit=t) for i, t in zip(top_k, tmp_circuits)]\n",
    "\n",
    "    # Run final\n",
    "    aim_result = {}\n",
    "    for circ, inversion_arr in zip(tmp_circuits, top_k):\n",
    "\n",
    "        job = execute(circ, backend, shots=confirmation_shots)\n",
    "        results = job.result().get_counts()\n",
    "\n",
    "        # Simulated Noisy Measurement\n",
    "        if probs is not None:\n",
    "            noisy_measurement = measurement_error(results, n_qubits=n_qubits, probs=probs)\n",
    "            results = sample_distribution(noisy_measurement, confirmation_shots)\n",
    "\n",
    "        for count in results:\n",
    "            # Invert measurement results using k strings\n",
    "            count_arr = ''.join(\n",
    "                map(str, [i ^ j for i, j in zip(map(int, list(inversion_arr)), map(int, list(count[::-1])))])\n",
    "            )\n",
    "\n",
    "            if count_arr in aim_result:\n",
    "                aim_result[count_arr] += results[count]\n",
    "            else:\n",
    "                aim_result[count_arr] = results[count]\n",
    "\n",
    "    return aim_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0416e2c1",
   "metadata": {},
   "source": [
    "### Tensor Calibration ###\n",
    "Calibrate each qubit individually, then tensor the calibration matricies\n",
    "Performs well against state dependence, but cannot detect correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-bulgarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ibmq_sliding_filter(circuit, probs=None, n_shots=1000, n_qubits=4) -> dict:\n",
    "    '''\n",
    "        ibmq_sliding_filter\n",
    "        Performs tensored measurement error calibration on a target circuit\n",
    "        :: circuit  :: Circuit to perform tensor calibration over\n",
    "        :: probs    :: Simulated error channel to apply\n",
    "        :: n_shots  :: Number of shots to take\n",
    "        :: n_qubits :: Number of qubits to measure\n",
    "        \n",
    "        Returns the shot statistics following measurement error calibration\n",
    "    '''\n",
    "\n",
    "    # Shots per calibration circuit, 50% of shots for building the filter\n",
    "    shots = n_shots // (2 ** (n_qubits)) \n",
    "    \n",
    "    # Confirmation shots after calibration\n",
    "    confirmation_shots = n_shots \n",
    "    \n",
    "    # Build Calibration Matrix\n",
    "    if n_qubits % 2:\n",
    "        mit_pattern = [[i, i + 1] for i in range(0, n_qubits - 3, 2)] \n",
    "        mit_pattern += [[n_qubits - 3, n_qubits - 2, n_qubits - 1]]\n",
    "    else:\n",
    "        mit_pattern = [[i, i + 1] for i in range(0, n_qubits, 2)]\n",
    "        \n",
    "    qr = QuantumRegister(n_qubits)\n",
    "    meas_calibs, state_labels = tensored_meas_cal(mit_pattern=mit_pattern, qr=qr, circlabel='mcal')\n",
    "\n",
    "    t_qc = transpile(meas_calibs, backend)\n",
    "    qobj = assemble(t_qc, shots = shots)\n",
    "    cal_results = backend.run(qobj, shots=n_shots).result()\n",
    "\n",
    "    # Apply measurement errors to cal results\n",
    "    if probs is not None:\n",
    "        cal_res_measurement_error(cal_results, probs, n_qubits=n_qubits)\n",
    "\n",
    "    # Pass results to the IBM fitter\n",
    "    meas_fitter = TensoredMeasFitter(cal_results, state_labels, circlabel='mcal')\n",
    "\n",
    "    # Add measurements to circuit\n",
    "    circuit = design_circuit(n_qubits, '0' * n_qubits, circuit=circuit)\n",
    "\n",
    "    # Once the fitter is constructed, attempt the real experiments\n",
    "    job = execute(circuit, backend, shots=confirmation_shots)\n",
    "    result = job.result()\n",
    "    \n",
    "    # Simulated measurement errors\n",
    "    if probs is not None:\n",
    "        cal_res_measurement_error(result, probs, n_qubits=n_qubits)\n",
    "    \n",
    "    qiskit_results = meas_fitter.filter.apply(result).get_counts()\n",
    "    \n",
    "    # Results are in reverse order\n",
    "    qiskit_results_qubit_order = {}\n",
    "    for i in qiskit_results:\n",
    "        qiskit_results_qubit_order[i[::-1]] = qiskit_results[i]\n",
    "    return qiskit_results_qubit_order\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383cb610",
   "metadata": {},
   "source": [
    "### Full Calibration ###\n",
    "Basically process tomography for the measurement basis, scales exponentially in the number of qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a449a414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ibmq_filter(circuit, n_shots=1000, probs=None, n_qubits=4) -> dict:\n",
    "    '''\n",
    "        ibmq_filter\n",
    "        Performs all qubit measurement error calibration on a target circuit\n",
    "        \n",
    "        :: circuit  :: Circuit to perform measurement error calibration over\n",
    "        :: probs    :: Simulated error channel to apply\n",
    "        :: n_shots  :: Number of shots to take\n",
    "        :: n_qubits :: Number of qubits to measure\n",
    "        \n",
    "        Returns the shot statistics following calibration\n",
    "    '''\n",
    "    \n",
    "    # Shots per calibration circuit, 50% of shots for building the filter\n",
    "    shots = n_shots // (2 ** (n_qubits)) \n",
    "    \n",
    "    # Confirmation shots to use with the filter\n",
    "    confirmation_shots = n_shots \n",
    "    \n",
    "    # Build Calibration Matrix\n",
    "    qr = QuantumRegister(4)\n",
    "    meas_calibs, state_labels = complete_meas_cal(qr=qr, circlabel='mcal')\n",
    "\n",
    "    t_qc = transpile(meas_calibs, backend)\n",
    "    qobj = assemble(t_qc, shots = shots)\n",
    "    cal_results = backend.run(qobj, shots=shots).result()\n",
    "    \n",
    "    if probs is not None:\n",
    "        # Apply measurement biases to cal results\n",
    "        cal_res_measurement_error(cal_results, probs, n_qubits=n_qubits)\n",
    "    \n",
    "    # Pass results to the IBM fitter\n",
    "    meas_fitter = CompleteMeasFitter(cal_results, state_labels, circlabel='mcal')\n",
    "\n",
    "    # Add measurements to circuit\n",
    "    circuit = design_circuit(n_qubits, '0' * n_qubits, circuit=circuit)\n",
    "\n",
    "    # Once the fitter is constructed, attempt the real experiments\n",
    "    job = execute(circuit, backend, shots=confirmation_shots)\n",
    "    result = job.result()\n",
    "    \n",
    "    if probs is not None:\n",
    "        cal_res_measurement_error(result, probs, n_qubits=n_qubits)\n",
    "\n",
    "    result = meas_fitter.filter.apply(result).get_counts()\n",
    "    \n",
    "    # Results are in reverse order\n",
    "    qiskit_results_qubit_order = {}\n",
    "    for i in result:\n",
    "        qiskit_results_qubit_order[i[::-1]] = result[i]\n",
    "    return qiskit_results_qubit_order\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef622167",
   "metadata": {},
   "source": [
    "### Coupling Map Calibration [New Method] ###\n",
    "Performs calibration over adjacent pairs on the coupling map\n",
    "Better scaling than exponential while preserving local correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2c99c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def composite_map(backend, n_qubits=4, probs=None, n_shots=1000, assert_accuracy=False, coupling_map=None):\n",
    "    '''\n",
    "        Build a composite map fitter given a backend and a coupling map\n",
    "        \n",
    "        :: backend  :: Backend object with associated coupling map\n",
    "        :: probs    :: Simulated error channel to apply\n",
    "        :: n_shots  :: Number of shots to take\n",
    "        :: n_qubits :: Number of qubits to measure\n",
    "        :: assert_accuracy :: Check accuracy of approximation\n",
    "        :: coupling_map :: Coupling map if backend does not have one\n",
    "        \n",
    "        Returns a composite map calibration filter\n",
    "    '''\n",
    "    \n",
    "    # Converts coupling map tuples to integers\n",
    "    cmap_to_mit = lambda x, y: x * n_qubits + y\n",
    "\n",
    "    # Build a register for calibrations\n",
    "    qr = qiskit.QuantumRegister(n_qubits)\n",
    "\n",
    "    # Fix our qubit layout\n",
    "    initial_layout = {}\n",
    "    for i in range(n_qubits):\n",
    "        initial_layout[qr[i]] = i\n",
    "\n",
    "    # Unique Assignment and clear duplicates\n",
    "    mit_patterns = {}\n",
    "    \n",
    "    # Coupling map override\n",
    "    if coupling_map is None:\n",
    "        coupling_map = backend.configuration().coupling_map\n",
    "        \n",
    "    for pat in coupling_map:\n",
    "        # Cull couplings with qubits that aren't in our register\n",
    "        out_of_scope = False\n",
    "        for i in pat:\n",
    "            if i >= n_qubits:\n",
    "                out_of_scope = True\n",
    "        \n",
    "        # Cull duplicate couplings\n",
    "        if not out_of_scope:\n",
    "            if cmap_to_mit(*pat) not in mit_patterns and cmap_to_mit(*pat[::-1]) not in mit_patterns:\n",
    "                mit_patterns[cmap_to_mit(*pat)] = pat\n",
    "    \n",
    "    \n",
    "    # Number of shots per trial\n",
    "    shots = n_shots // (len(mit_patterns) * 4)\n",
    "\n",
    "    # Approximate two qubit error channel for calibration\n",
    "    if probs is not None:\n",
    "        pair_probs = np.array(probs)[:4, :4]\n",
    "\n",
    "    \n",
    "    qubit_pair_fitters = {}\n",
    "    for pat in mit_patterns:\n",
    "        \n",
    "        # Construct calibration circuits\n",
    "        meas_calibs, state_labels = tensored_meas_cal(mit_pattern=[mit_patterns[pat]], qr=qr, circlabel='mcal')\n",
    "        meas_calibs_t = transpile(meas_calibs, initial_layout=initial_layout, optimization_level=0)\n",
    "        \n",
    "        # Execute calibration circuits independently\n",
    "        # Running simultaneously may result in later experiments being shortchanged on shots\n",
    "        calibration_results = [execute(i, backend, shots=shots).result() for i in meas_calibs_t]\n",
    "        \n",
    "        # Join into one results object\n",
    "        calibration_results[0].results += [i.results[0] for i in calibration_results[1:]]\n",
    "        calibration_result = calibration_results[0]\n",
    "        \n",
    "        # Apply any simulated measurement errors\n",
    "        if probs is not None:\n",
    "            cal_res_measurement_error(calibration_result, pair_probs, n_qubits=2)\n",
    "        \n",
    "        fitter = TensoredMeasFitter(calibration_result, state_labels, circlabel='mcal')\n",
    "        qubit_pair_fitters[pat] = fitter.cal_matrices[0]\n",
    "\n",
    "        \n",
    "   # Join calibration matrices\n",
    "    for i in range(n_qubits):\n",
    "\n",
    "        # Count number of participating matricies\n",
    "        num_participants = 0\n",
    "        for j in mit_patterns:\n",
    "            if i in mit_patterns[j]:\n",
    "                num_participants += 1\n",
    "\n",
    "        # Modify for general construction beyond pairs\n",
    "        participant_num = 0 # Order of construction\n",
    "        for pat in mit_patterns:\n",
    "            if i in mit_patterns[pat]:\n",
    "\n",
    "                position = mit_patterns[pat].index(i)\n",
    "\n",
    "                cal_matrix = Qobj(qubit_pair_fitters[pat], dims=f_dims(2))\n",
    "\n",
    "                # Ptrace to approximate the target qubit\n",
    "                single_qubit_approx = normalise(np.array(cal_matrix.ptrace(position)))\n",
    "\n",
    "                # Construct left and right approximations\n",
    "                mean_approx_l = scipy.linalg.fractional_matrix_power(\n",
    "                    normalise(np.array(single_qubit_approx)),\n",
    "                    (num_participants - 1 - participant_num) / num_participants\n",
    "                )\n",
    "\n",
    "                mean_approx_r = scipy.linalg.fractional_matrix_power(\n",
    "                    normalise(np.array(single_qubit_approx)),\n",
    "                    participant_num / num_participants\n",
    "                )\n",
    "            \n",
    "                # Check accuracy of approximation\n",
    "                if assert_accuracy:\n",
    "                    assert(np.linalg.norm(\n",
    "                         mean_approx_l \n",
    "                       @ scipy.linalg.fractional_matrix_power(single_qubit_approx, 1 / num_participants)\n",
    "                       @ mean_approx_r\n",
    "                       - single_qubit_approx\n",
    "                    ) < 1e-4)\n",
    "\n",
    "                # Expand and set to the correct terms, currently in order [a, b, I, I, I ...]\n",
    "                expanded_approx_l = [np.eye(2) for _ in range(len(mit_patterns[pat]) - 1)]\n",
    "                expanded_approx_l = np.kron(mean_approx_l, expanded_approx_l)\n",
    "                expanded_approx_l = Qobj(expanded_approx_l[0], dims=f_dims(len(mit_patterns[pat])))\n",
    "\n",
    "                expanded_approx_r = [np.eye(2) for _ in range(len(mit_patterns[pat]) - 1)]\n",
    "                expanded_approx_r = np.kron(mean_approx_r, expanded_approx_r)\n",
    "                expanded_approx_r = Qobj(expanded_approx_r[0], dims=f_dims(len(mit_patterns[pat])))\n",
    "\n",
    "                # Construct permutation order\n",
    "                order = list(range(len(mit_patterns[pat])))\n",
    "                order[position] = 0\n",
    "                order[0] = position\n",
    "\n",
    "                # Permute to correct order\n",
    "                expanded_approx_l = expanded_approx_l.permute(order)\n",
    "                expanded_approx_r = expanded_approx_r.permute(order)\n",
    "\n",
    "                # Convert back to numpy array\n",
    "                expanded_approx_l = np.array(expanded_approx_l)\n",
    "                expanded_approx_r = np.array(expanded_approx_r)\n",
    "\n",
    "                qubit_pair_fitters[pat] = (\n",
    "                      np.linalg.inv(expanded_approx_l) \n",
    "                    @ qubit_pair_fitters[pat] \n",
    "                    @ np.linalg.inv(expanded_approx_r)\n",
    "                )\n",
    "\n",
    "                participant_num += 1\n",
    "\n",
    "    # Doesn't need sparse matricies for small devices\n",
    "    for pat in mit_patterns:\n",
    "\n",
    "        pair = mit_patterns[pat]\n",
    "        pair_approx = qubit_pair_fitters[pat]\n",
    "\n",
    "        expanded_approx = reduce(np.kron, [pair_approx] + [np.eye(2)] * (n_qubits - len(pair)))\n",
    "        expanded_approx = Qobj(expanded_approx, dims=[[2 for i in range(n_qubits)]] * 2)\n",
    "\n",
    "        # Construct ordering for permutation\n",
    "        # First n elements of the expanded approximation are non-identity and need to be correctly swapped\n",
    "        # Last k elements are all the identity and may be freely interchanged\n",
    "        order = []\n",
    "        order_count = len(pair)\n",
    "        pair_count = 0\n",
    "        for i in range(n_qubits):\n",
    "            if i in pair:\n",
    "                order.append(pair_count)\n",
    "                pair_count += 1\n",
    "            else:\n",
    "                order.append(order_count)\n",
    "                order_count += 1\n",
    "\n",
    "        # Apply permutation\n",
    "        expanded_approx = np.array(expanded_approx.permute(order))\n",
    "        qubit_pair_fitters[pat] = expanded_approx\n",
    "\n",
    "    # Base calibration matrix\n",
    "    cal_matrix = np.eye(2 ** n_qubits)\n",
    "    for pat in mit_patterns:\n",
    "        cal_matrix = qubit_pair_fitters[pat] @ cal_matrix\n",
    "    \n",
    "    cal_matrix = np.real(cal_matrix)\n",
    "        \n",
    "    # Build new cal matrix object:\n",
    "    state_labels = [str(bin(i)[2:]).zfill(n_qubits) for i in range(2 ** n_qubits)]\n",
    "    fitter = CompleteMeasFitter(results=None, state_labels=state_labels)\n",
    "    \n",
    "    # Set the corresponding objects appropriately\n",
    "    fitter._tens_fitt.cal_matrices = [cal_matrix]\n",
    "    return fitter\n",
    "\n",
    "\n",
    "def composite_filter(circuit, probs=None, n_shots=1000, n_qubits=4, **kwargs):\n",
    "    '''\n",
    "        composite_filter\n",
    "        Performs all qubit measurement error calibration on a target circuit \n",
    "        Using coupling map pairs to build a composite filter\n",
    "        \n",
    "        :: circuit  :: Circuit to perform measurement error calibration over\n",
    "        :: probs    :: Simulated error channel to apply\n",
    "        :: n_shots  :: Number of shots to take\n",
    "        :: n_qubits :: Number of qubits to measure\n",
    "        \n",
    "        Returns the shot statistics following calibration\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    shots = n_shots # 50% of shots on building the filter\n",
    "    confirmation_shots = n_shots \n",
    "    \n",
    "    # Build Calibration Matrix\n",
    "    qr = QuantumRegister(n_qubits)\n",
    "    meas_calibs, state_labels = complete_meas_cal(qr=qr, circlabel='mcal')\n",
    "    \n",
    "    # Build the filter\n",
    "    comp_filter = composite_map(backend, n_qubits=n_qubits, probs=probs, n_shots=shots, **kwargs)\n",
    "    \n",
    "    # Add measurements to circuit\n",
    "    circuit = design_circuit(n_qubits, '0' * n_qubits, circuit=circuit)\n",
    "\n",
    "    # Once the fitter is constructed, attempt the real experiments\n",
    "    job = execute(circuit, backend, shots=confirmation_shots)\n",
    "    result = job.result()\n",
    "    \n",
    "    if probs is not None:\n",
    "        cal_res_measurement_error(result, probs, n_qubits=n_qubits)\n",
    "        \n",
    "    result = comp_filter.filter.apply(result).get_counts()\n",
    "    \n",
    "    # Results are in reverse order\n",
    "    qiskit_results_qubit_order = {}\n",
    "    for i in result:\n",
    "        qiskit_results_qubit_order[i[::-1]] = result[i]\n",
    "    return qiskit_results_qubit_order\n",
    "\n",
    "\n",
    "\n",
    "def normalise(x):\n",
    "    '''\n",
    "        Normalise the partial trace of a calibration matrix\n",
    "    '''\n",
    "    for i in range(x.shape[1]):\n",
    "        tot = sum(x[:, i])\n",
    "        if tot != 0:\n",
    "            x[:, i] /= tot\n",
    "    return x\n",
    "\n",
    "def f_dims(n):\n",
    "    '''\n",
    "        Dimension ordering for n qubits\n",
    "    '''\n",
    "    return [[2 for i in range(n)]] * 2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08421b9f",
   "metadata": {},
   "source": [
    "## Experiment Runner ##\n",
    "Runs an error mitigation method over an optional simulated error channel and a number of shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f66c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_shots_bv(\n",
    "    shots_vec : list, # Vector of shots\n",
    "    fn : Callable,    # Error mitigation function\n",
    "    *args,\n",
    "    probs=None,       # Simulated error probabilities\n",
    "    n_qubits=4,       # Number of qubits\n",
    "    prog=True,        # Progress Bar\n",
    "    plabel='Scaling', # Progress Bar Label\n",
    "    **kwargs\n",
    "):\n",
    "    \n",
    "    '''\n",
    "        Apply error mitigation methods over a range of total numbers of shots\n",
    "        \n",
    "        :: fn        :: Error mitigation method\n",
    "        :: shots_vec :: Vector of a range of numbers of shots\n",
    "        :: probs     :: Simulated measurement errors \n",
    "        :: n_qubits  :: Number of qubits to measure\n",
    "        :: prog      :: Progress bar\n",
    "        :: plabel    :: Label on progress bar\n",
    "        \n",
    "        Returns the data along with the number of shots associated with each point\n",
    "    '''\n",
    "    \n",
    "    data = []\n",
    "\n",
    "    # Progress bar\n",
    "    prog = Pbar(20, 2 ** n_qubits, plabel)\n",
    "    \n",
    "    # For each bv string\n",
    "    for b_str in range(2 ** n_qubits):\n",
    "        \n",
    "        # Construct BV target string\n",
    "        bv_string = bin(b_str)[2:].zfill(n_qubits)    \n",
    "        \n",
    "        # Tick progress bar\n",
    "        prog(bv_string)\n",
    "        \n",
    "        # Construct circuit\n",
    "        circuit = bv_circuit(bv_string, n_qubits + 1)\n",
    "\n",
    "        # Apply shots over the range of shots\n",
    "        scale = map(lambda i : fn(circuit, *args, probs=probs, n_shots=i, **kwargs), shots_vec)\n",
    "        \n",
    "        # Collect data\n",
    "        data += list(np.array([i[bv_string] if bv_string in i else 0 for i in scale]) / np.array(shots_vec))\n",
    "                \n",
    "    x_points = np.kron(np.ones(2 ** n_qubits), np.array(shots_vec))\n",
    "    print()\n",
    "    return x_points, data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6c19c7",
   "metadata": {},
   "source": [
    "# Experiments #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-citizenship",
   "metadata": {},
   "source": [
    "#### Experiment: ####\n",
    "Simulated error channel with distance 1 errors\n",
    "\n",
    "Will take several hours to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-acceptance",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = Aer.get_backend(\"qasm_simulator\")\n",
    "\n",
    "n_qubits = 4\n",
    "probs = gen_error_probs(\n",
    "        [100,5,0,0,0], # Const - Controls correlation of error weights\n",
    "        [0, 0, 0, 0, 0], # 1 -> 0 - Controls error biases\n",
    "        [0, 0, 0, 0, 0] # 0 -> 1 - Controls error biases\n",
    "        )\n",
    "shots_vec = range(1000, 16000, 50)\n",
    "\n",
    "sbs.heatmap(probs)\n",
    "\n",
    "# Fake coupling map\n",
    "coupling_map = [[i, i + 1] for i in range(n_qubits)]\n",
    "\n",
    "x_points, sim_data_d1 = scale_shots_bv(shots_vec, sim, probs=probs, plabel='SIM')\n",
    "x_points, aim_data_d1 = scale_shots_bv(shots_vec, aim, probs=probs, plabel='AIM')\n",
    "x_points, ibmq_data_d1 = scale_shots_bv(shots_vec, ibmq_filter, probs=probs, plabel='IBMQ')\n",
    "x_points, ibmqs_data_d1 = scale_shots_bv(shots_vec, ibmq_sliding_filter, probs=probs, plabel='IBMQ Sliding')\n",
    "x_points, comp_data_d1 = scale_shots_bv(shots_vec, composite_filter, probs=probs, coupling_map=coupling_map, plabel='CMAP')\n",
    "x_points, base_data_d1 = scale_shots_bv(shots_vec, no_correction, probs=probs, plabel='Base')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-organization",
   "metadata": {},
   "source": [
    "#### Plotting ####\n",
    "Histplots of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-buying",
   "metadata": {},
   "outputs": [],
   "source": [
    "shots_vec = range(1000, 16000, 50)\n",
    "\n",
    "x_points = np.kron(np.ones(2 ** n_qubits), np.array(shots_vec))\n",
    "\n",
    "ax = sbs.histplot(x=x_points, y=base_data_d1, color='green')\n",
    "sbs.histplot(x=x_points, y=np.array(ibmq_data_d1), color='orange')\n",
    "sbs.histplot(x=x_points, y=np.array(base_data_d1), color='green')\n",
    "sbs.histplot(x=x_points, y=sim_data_d1)\n",
    "sbs.histplot(x=x_points, y=np.array(aim_data_d1), color='red')\n",
    "\n",
    "#ax.set(xlim=(0, 16000))\n",
    "plt.title('Distance 1 IID Errors')\n",
    "plt.xlabel(\"Total Measurements\")\n",
    "plt.ylabel(\"Success Probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dda7aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 4\n",
    "x_points = np.kron(np.ones(2 ** n_qubits), np.array(shots_vec))\n",
    "ax = sbs.histplot(x=x_points, y=np.array(base_data_d1), color='green')\n",
    "#ax.set(ylim=(0.799, 1.01))\n",
    "\n",
    "#plt.text(7000, 0.86, 'Unmitigated')\n",
    "\n",
    "plt.title('Distance 1 IID Errors')\n",
    "plt.xlabel(\"Total Shots\")\n",
    "plt.ylabel(\"Success Probability\")\n",
    "\n",
    "#plt.savefig('1_IID_base.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b839cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 4\n",
    "x_points = np.kron(np.ones(2 ** n_qubits), np.array(shots_vec))\n",
    "ax = sbs.histplot(x=x_points, y=np.array(aim_data_d1), color='red')\n",
    "sbs.histplot(x=x_points, y=np.array(ibmq_data_d1), color='orange', ax=ax)\n",
    "ax.set(ylim=(0.799, 1.01))\n",
    "\n",
    "#plt.text(6000, 0.97, 'All Qubit Calibration')\n",
    "#plt.text(8000, 0.86, 'AIM')\n",
    "\n",
    "plt.title('Distance 1 IID Errors')\n",
    "plt.xlabel(\"Total Shots\")\n",
    "plt.ylabel(\"Success Probability\")\n",
    "\n",
    "#plt.savefig('1_IID_aim_all.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef10ffe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 4\n",
    "x_points = np.kron(np.ones(2 ** n_qubits), np.array(shots_vec))\n",
    "ax = sbs.histplot(x=x_points, y=np.array(sim_data_d1), color='blue', label='SIM')\n",
    "sbs.histplot(x=x_points, y=np.array(ibmqs_data_d1), color='yellow', label='Linear Calibration', ax=ax)\n",
    "ax.set(ylim=(0.799, 1.01))\n",
    "\n",
    "plt.title('Distance 1 IID Errors')\n",
    "plt.xlabel(\"Total Shots\")\n",
    "plt.ylabel(\"Success Probability\")\n",
    "\n",
    "#plt.text(6000, 0.96, 'Single Qubit Calibration')\n",
    "#plt.text(8000, 0.86, 'SIM')\n",
    "\n",
    "#plt.savefig('1_IID_sim_lin.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384f066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 4\n",
    "x_points = np.kron(np.ones(2 ** n_qubits), np.array(shots_vec))\n",
    "ax = sbs.histplot(x=x_points, y=np.array(base_data_d1), color='green')\n",
    "ax.set(ylim=(0.799, 1.01))\n",
    "\n",
    "plt.title('Distance 1 IID Errors Uncorrected')\n",
    "plt.xlabel(\"Total Measurements\")\n",
    "plt.ylabel(\"Success Probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03f4ead",
   "metadata": {},
   "source": [
    "#### Experiment: ####\n",
    "Distance 2 error channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-olive",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = Aer.get_backend(\"qasm_simulator\")\n",
    "shots_vec = range(1000, 16000, 50)\n",
    "\n",
    "probs = gen_error_probs(\n",
    "        [100, 0, 5,0,0], # Const - Controls correlation of error weights\n",
    "        [0, 0, 0, 0, 0], # 1 -> 0 - Controls error biases\n",
    "        [0, 0, 0, 0, 0] # 0 -> 1 - Controls error biases\n",
    "        )\n",
    "\n",
    "# Fake coupling map\n",
    "coupling_map = [[i, i + 1] for i in range(n_qubits)]\n",
    "\n",
    "# Plot heatmap\n",
    "sbs.heatmap(probs)\n",
    "\n",
    "x_points, sim_data_d2 = scale_shots_bv(shots_vec, sim, probs=probs, plabel='SIM')\n",
    "x_points, aim_data_d2 = scale_shots_bv(shots_vec, aim, probs=probs, plabel='AIM')\n",
    "x_points, ibmq_data_d2 = scale_shots_bv(shots_vec, ibmq_filter, probs=probs, plabel='IBMQ')\n",
    "x_points, ibmqs_data_d2 = scale_shots_bv(shots_vec, ibmq_sliding_filter, probs=probs, plabel='IBMQ Sliding')\n",
    "x_points, comp_data_d2 = scale_shots_bv(shots_vec, composite_filter, probs=probs, coupling_map=coupling_map, plabel='CMAP')\n",
    "x_points, base_data_d2 = scale_shots_bv(shots_vec, no_correction, probs=probs, plabel='Base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01099b67",
   "metadata": {},
   "source": [
    "#### Plotting ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-workshop",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sbs.histplot(x=x_points, y=base_data_d2, color='green')\n",
    "sbs.histplot(x=x_points, y=np.array(sim_data_d2), color='blue', ax=ax)\n",
    "sbs.histplot(x=x_points, y=np.array(aim_data_d2), color='red', ax=ax)\n",
    "sbs.histplot(x=x_points, y=np.array(ibmq_data_d2), color='orange', ax=ax)\n",
    "#ax.set(xlim=(0, 16000), ylim=(0.6, 1.0))\n",
    "plt.title('Distance 2 Correlated Errors')\n",
    "plt.xlabel(\"Total Measurements\")\n",
    "plt.ylabel(\"Success Probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cebb80",
   "metadata": {},
   "source": [
    "#### Experiment: ####\n",
    "Single qubit state dependent errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-effort",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = Aer.get_backend(\"qasm_simulator\")\n",
    "shots_vec = range(1000, 16000, 50)\n",
    "\n",
    "probs = gen_error_probs(\n",
    "        [100, 1, 0,0,0], # Const - Controls correlation of error weights\n",
    "        [0, 1, 0, 0, 0], # 1 -> 0 - Controls error biases\n",
    "        [0, 0, 0, 0, 0] # 0 -> 1 - Controls error biases\n",
    "        )\n",
    "sbs.heatmap(probs)\n",
    "\n",
    "# Fake coupling map for simulator\n",
    "coupling_map = [[i, i + 1] for i in range(n_qubits)]\n",
    "\n",
    "\n",
    "x_points, sim_data_b1 = scale_shots_bv(shots_vec, sim, probs=probs, plabel='SIM')\n",
    "x_points, aim_data_b1 = scale_shots_bv(shots_vec, aim, probs=probs, plabel='AIM')\n",
    "x_points, ibmq_data_b1 = scale_shots_bv(shots_vec, ibmq_filter, probs=probs, plabel='IBMQ')\n",
    "x_points, ibmqs_data_b1 = scale_shots_bv(shots_vec, ibmq_sliding_filter, probs=probs, plabel='IBMQ Sliding')\n",
    "x_points, comp_data_b1 = scale_shots_bv(shots_vec, composite_filter, probs=probs, coupling_map=coupling_map, plabel='CMAP')\n",
    "x_points, base_data_b1 = scale_shots_bv(shots_vec, no_correction, probs=probs, plabel='Base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-links",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_points = np.kron(np.ones(2 ** n_qubits), np.array(shots_vec))\n",
    "ax=sbs.histplot(x=x_points, y=base_data_b1, color='green')\n",
    "#sbs.histplot(x=x_points, y=sim_data_b1, color=\"blue\", ax=ax)\n",
    "#sbs.histplot(x=x_points, y=aim_data_b1, color=\"red\", ax=ax)\n",
    "#sbs.histplot(x=x_points, y=ibmq_data_b1, color='orange', ax=ax)\n",
    "\n",
    "#plt.text(7000, 0.97, 'Unmitigated')\n",
    "ax.set(ylim=(0.83, 1.0))\n",
    "\n",
    "plt.title('Simulated State Dependent Measurement Errors')\n",
    "plt.xlabel(\"Total Shots\")\n",
    "plt.ylabel(\"Success Probability\")\n",
    "#plt.savefig('biased_based.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc98610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_points = np.kron(np.ones(2 ** n_qubits), np.array(shots_vec))\n",
    "#ax=sbs.histplot(x=x_points, y=sim_data_b1, color='blue')\n",
    "ax=sbs.histplot(x=x_points, y=sim_data_b1, color=\"blue\")\n",
    "sbs.histplot(x=x_points, y=aim_data_b1, color=\"red\", ax=ax)\n",
    "sbs.histplot(x=x_points, y=ibmq_data_b1, color='orange', ax=ax)\n",
    "\n",
    "# plt.text(7000, 0.98, 'Calibration')\n",
    "# plt.text(8000, 0.948, 'SIM')\n",
    "# plt.text(8000, 0.87, 'AIM')\n",
    "ax.set(ylim=(0.83, 1.0))\n",
    "\n",
    "plt.title('State Dependent Measurement Error Mitigation')\n",
    "plt.xlabel(\"Total Shots\")\n",
    "plt.ylabel(\"Success Probability\")\n",
    "plt.savefig('biased_suppression.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bc4ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Error Rates Single Qubit State Dependent Noise\")\n",
    "print('Base: \\t\\t\\t\\t', 1 - np.mean(base_data_b1))\n",
    "print('SIM: \\t\\t\\t\\t', 1 - np.mean(sim_data_b1))\n",
    "print('AIM: \\t\\t\\t\\t', 1 - np.mean(aim_data_b1))\n",
    "print('Calibration: \\t\\t\\t',  1 - np.mean(ibmq_data_b1))\n",
    "print('Tensor Calibration: \\t\\t',  1 - np.mean(ibmqs_data_b1))\n",
    "print('Coupling Map Calibration: \\t',  1 - np.mean(comp_data_b1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24958824",
   "metadata": {},
   "source": [
    "#### Experiment ####\n",
    "Single qubit errors with small state dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-password",
   "metadata": {},
   "outputs": [],
   "source": [
    "shots_vec = range(100, 16000, 100)\n",
    "\n",
    "probs = gen_error_probs(\n",
    "        [100, 1, 0,0,0], # Const - Controls correlation of error weights\n",
    "        [0, 1, 0, 0, 0], # 1 -> 0 - Controls error biases\n",
    "        [0, 0, 0, 0, 0] # 0 -> 1 - Controls error biases\n",
    "        )\n",
    "sbs.heatmap(probs)\n",
    "x_points, sim_data_b2 = scale_shots_bv(shots_vec, sim, probs=probs, plabel='SIM')\n",
    "x_points, aim_data_b2 = scale_shots_bv(shots_vec, aim, probs=probs, plabel='AIM')\n",
    "x_points, ibmq_data_b2 = scale_shots_bv(shots_vec, ibmq_filter, probs=probs, plabel='IBMQ')\n",
    "x_points, ibmqs_data_b2 = scale_shots_bv(shots_vec, ibmq_sliding_filter, probs=probs, plabel='IBMQ Sliding')\n",
    "x_points, comp_data_b2 = scale_shots_bv(shots_vec, composite_filter, probs=probs, coupling_map=coupling_map, plabel='CMAP')\n",
    "x_points, base_data_b2 = scale_shots_bv(shots_vec, no_correction, probs=probs, plabel='Base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a3e23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Error Rates Single Qubit State Dependent + Single Qubit IID Noise\")\n",
    "print('Base: \\t\\t\\t\\t', 1 - np.mean(base_data_b2))\n",
    "print('SIM: \\t\\t\\t\\t', 1 - np.mean(sim_data_b2))\n",
    "print('AIM: \\t\\t\\t\\t', 1 - np.mean(aim_data_b2))\n",
    "print('Calibration: \\t\\t\\t',  1 - np.mean(ibmq_data_b2))\n",
    "print('Tensor Calibration: \\t\\t',  1 - np.mean(ibmqs_data_b2))\n",
    "print('Coupling Map Calibration: \\t',  1 - np.mean(comp_data_b2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0cf45e",
   "metadata": {},
   "source": [
    "#### Experiment ####\n",
    "Just testing a very messy correlated and state dependent set of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-collar",
   "metadata": {},
   "outputs": [],
   "source": [
    "shots_vec = range(100, 16000, 100)\n",
    "\n",
    "probs = gen_error_probs(\n",
    "        [100,0,10,0,0], # Const - Controls correlation of error weights\n",
    "        [0, 5, 30, 5, 5], # 1 -> 0 - Controls error biases\n",
    "        [0,-20,-20,-20,-20] # 0 -> 1 - Controls error biases\n",
    "        )\n",
    "\n",
    "sbs.heatmap(probs)\n",
    "\n",
    "x_points, sim_data_g1 = scale_shots_bv(shots_vec, sim, probs=probs, plabel='SIM')\n",
    "x_points, aim_data_g1 = scale_shots_bv(shots_vec, aim, probs=probs, plabel='AIM')\n",
    "x_points, ibmq_data_g1 = scale_shots_bv(shots_vec, ibmq_filter, probs=probs, plabel='IBMQ')\n",
    "x_points, ibmqs_data_g1 = scale_shots_bv(shots_vec, ibmq_sliding_filter, probs=probs, plabel='IBMQ Sliding')\n",
    "x_points, comp_data_g1 = scale_shots_bv(shots_vec, composite_filter, probs=probs, coupling_map=coupling_map, plabel='CMAP')\n",
    "x_points, base_data_g1 = scale_shots_bv(shots_vec, no_correction, probs=probs, plabel='Base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-filing",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbs.set(style=\"darkgrid\")\n",
    "shots_vec = range(100, 16000, 100)\n",
    "\n",
    "x_points = np.kron(np.ones(2 ** n_qubits), np.array(shots_vec))\n",
    "ax=sbs.histplot(x=x_points, y=base_data_g1, color='green')\n",
    "sbs.histplot(x=x_points, y=ibmq_data_g1, color='orange', ax=ax)\n",
    "#sbs.histplot(x=x_points, y=sim_data_g1, color=\"blue\", ax=ax)\n",
    "\n",
    "\n",
    "#plt.text(6500, 0.9, 'Calibration Full')\n",
    "#plt.text(8000, 0.8, 'SIM')\n",
    "#plt.text(6500, 0.75, 'Unmitigated')\n",
    "\n",
    "#plt.text()\n",
    "#plt.text(8000, 0.87, 'AIM')\n",
    "\n",
    "ax.set(ylim=(0.3, 1.0))\n",
    "\n",
    "plt.title('Correlated and State Dependent Errors')\n",
    "plt.xlabel(\"Total Measurements\")\n",
    "plt.ylabel(\"Success Probability\")\n",
    "plt.savefig(\"example_2_base.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34ffe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbs.set(style=\"darkgrid\")\n",
    "shots_vec = range(100, 16000, 100)\n",
    "\n",
    "x_points = np.kron(np.ones(2 ** n_qubits), np.array(shots_vec))\n",
    "ax=sbs.histplot(x=x_points, y=comp_data_g1, color='yellow')\n",
    "sbs.histplot(x=x_points, y=aim_data_g1, color=\"red\", ax=ax)\n",
    "sbs.histplot(x=x_points, y=sim_data_g1, color=\"blue\", ax=ax)\n",
    "\n",
    "#plt.text(4500, 0.93, 'Coupling Map Calibration')\n",
    "#plt.text(7500, 0.85, 'AIM')\n",
    "#plt.text(7500, 0.60, 'SIM')\n",
    "\n",
    "#plt.grid(b=None)\n",
    "\n",
    "ax.set(ylim=(0.3, 1.0))\n",
    "plt.title('Correlated and State Dependent Error Mitigation')\n",
    "plt.xlabel(\"Total Measurements\")\n",
    "plt.ylabel(\"Success Probability\")\n",
    "#plt.savefig(\"example_2_comparisons.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93a1f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Error Rates Single Qubit State Dependent + Single Qubit IID Noise\")\n",
    "print('Base: \\t\\t\\t\\t', 1 - np.mean(base_data_g1))\n",
    "print('SIM: \\t\\t\\t\\t', 1 - np.mean(sim_data_g1))\n",
    "print('AIM: \\t\\t\\t\\t', 1 - np.mean(aim_data_g1))\n",
    "print('Calibration: \\t\\t\\t',  1 - np.mean(ibmq_data_g1))\n",
    "print('Tensor Calibration: \\t\\t',  1 - np.mean(ibmqs_data_g1))\n",
    "print('Coupling Map Calibration: \\t',  1 - np.mean(comp_data_g1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
